{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OFGaUXhrlu1kVMcxoG-Ad4VdQqsWH31E","timestamp":1719273172487}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nHwIo1Mw0sKW"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as thdat\n","import time\n"]},{"cell_type":"code","source":["A=torch. ones(3)\n","A.shape\n","\n","AA=torch.cat((A,A,A))\n","print(AA)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nd9KfmbN5RuT","executionInfo":{"status":"ok","timestamp":1719248694663,"user_tz":240,"elapsed":227,"user":{"displayName":"Youxuan Wei","userId":"06100885586754575702"}},"outputId":"b5fb19d0-dacf-4b54-e71e-788adaad7a04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"]}]},{"cell_type":"code","source":["#Make gradient ? not sure why this works\n","#theowolf code https://github.com/TheodoreWolf/pinns/blob/main/src/cooling/temp_pred.ipynb\n","\n","def grad(outputs, inputs):\n","    \"\"\"Computes the partial derivative of\n","    an output with respect to an input.\n","    Args:\n","        outputs: (N, 1) tensor\n","        inputs: (N, D) tensor\n","    \"\"\"\n","    return torch.autograd.grad(\n","        outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True)\n","\n","\n","#Make an NN\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class YWTry(torch.nn.Module):\n","    def __init__(\n","        self,\n","        input_dim,\n","        output_dim,\n","        epochs=1000,\n","        #loss=nn.MSELoss(),\n","        lr=1e-4,\n","        #loss2=None,\n","        loss2_weight=0.1,\n","    ): #-> None:\n","        super().__init__()\n","\n","        self.epochs = epochs\n","        #self.loss = loss\n","        self.loss2_weight = loss2_weight\n","        self.lr = lr\n","\n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, input_dim), #the linear transform part https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n","            nn.Tanh(), #the activation func I changed to tanh\n","            nn.Linear(input_dim, input_dim),\n","            nn.Tanh(),\n","            nn.Linear(input_dim, input_dim),\n","            nn.Tanh(),\n","            nn.Linear(input_dim, input_dim),\n","            nn.Tanh(),\n","        )\n","        self.out = nn.Linear(input_dim, output_dim) #the final transform\n","\n","    def forward(self, x):\n","        h = self.layers(x) #it gives you the input as transformed by the hidden layers of the neural networks\n","        out = self.out(h) #prints out the final product. 'out' as tensor\n","        return out\n","\n","\n","    def Train(self, X, y):\n","\n","        start=time.time()\n","        optimiser = optim.Adam(self.parameters(), lr=self.lr)\n","        self.train() #https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch\n","\n","        def loss_g(inputs, outputs):\n","          loss=(inputs-outputs)**2\n","          return loss.mean()\n","\n","        def loss_f(input):\n","          U=self.Model(input)\n","          a=grad(U,input)[0] #because it returns you a tuple\n","          Ut=a[0]\n","          Ux=a[1]\n","          #Uxx=torch.autograd.grad(Ux,input[0])\n","          return (Ut-U*Ux)**2\n","              # U_partials=torch.autograd.grad(nnpred, inputs, grad_outputs=torch.ones_like(nnpred), retain_graph=True, create_graph=True)[0] #grad against inputs\n","              # Ut=U_partials[:,1] #grad against the time component, all rows, 2nd column\n","              # Ux=U_partials[:,0] #grad against space TAKES ONLY TENSORS as inputs\n","              # eq = (Ut-nnpred*Ux)**2 #1D burgers\\\n","\n","        for ep in range(self.epochs):\n","            optimiser.zero_grad()\n","            outputs = self.forward(X)\n","            i=random.randrange(2*N)\n","            loss = loss_g(y, outputs) + loss_f(cpts[i])\n","            #print(i)\n","            loss.backward()\n","            optimiser.step()\n","            if ep % int(self.epochs / 10) == 0:\n","                print(f\"Epoch {ep}/{self.epochs}, loss: {loss.item():.2f}\")\n","                print('time elapsed: {}'.format(time.time()-start))\n","        return ()\n","\n","    def Model(self, X):\n","        self.eval()\n","        out = self.forward(X)\n","        return out #.detach().cpu().numpy()\n","\n"],"metadata":{"id":"0DelOtlU1Wfy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#https://pytorch.org/docs/stable/generated/torch.autograd.grad.html\n","#autograd only takes against scalar products\n","x=torch.tensor([1,2,3], dtype=float, requires_grad=True)\n","y=torch.tensor([1,1,1], dtype=float, requires_grad=True)\n","z=torch.zeros(3)\n","z[0]=x[0]+x[2]\n","z[1]=x[1]*2\n","z[2]=x[2]*3\n","\n","\n","# z=2*x+y\n","#z.backward()\n","#Z0_x= torch.autograd.grad(z,x)[0]\n","def func(x):\n","  z = torch.zeros(3)\n","  z[0] = x[0]+x[2]\n","  z[1] = x[1]*2\n","  z[2] = x[2]*3\n","  return z\n","# https://pytorch.org/docs/stable/generated/torch.autograd.functional.jacobian.html\n","Z0_x = torch.autograd.functional.jacobian(func, x, create_graph=False, strict=False, vectorize=False, strategy='reverse-mode')\n","print(Z0_x)\n","type(Z0_x)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTV7CaSzazuW","executionInfo":{"status":"ok","timestamp":1719273496600,"user_tz":-480,"elapsed":314,"user":{"displayName":"Siyong Liu","userId":"11300406611691641646"}},"outputId":"4f7a6a40-e077-4c12-d424-9a9b4ec1014c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1.],\n","        [0., 2., 0.],\n","        [0., 0., 3.]], dtype=torch.float64)\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["print(type(cpts[3]))\n","a=torch.tensor([1,1])\n","a.shape\n","a[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHB4jVilgNNo","executionInfo":{"status":"ok","timestamp":1719259453278,"user_tz":240,"elapsed":216,"user":{"displayName":"Youxuan Wei","userId":"06100885586754575702"}},"outputId":"9bc2316a-04f8-4046-a885-643315aaa787"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(1)"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["#test data\n","N=100\n","import random\n","\n","#initial condition, t=0\n","inputinit = torch.column_stack((torch.tensor([random.random() for i in range(N)]), torch.zeros(N)))\n","print(inputinit.shape)\n","\n","#boundary condition, x=0, x=1, t is random in [0,1]\n","k=torch.hstack((torch.zeros(N), torch.ones(N)))\n","inputboundary = torch.column_stack((k, torch.tensor([random.random() for i in range(2*N)])))\n","\n","#output for initial condition\n","outputinit=torch.sin(np.pi*inputinit[:,0])\n","print(outputinit.shape)\n","#print(outputinit)\n","#output for no-penetrations conditions on boundary:\n","outputboundary= torch.zeros(2*N)\n","#print(outputboundary.shape)\n","\n","#collocation pts to check physics loss\n","cpts = torch.column_stack((torch.tensor([random.random() for i in range(2*N)], requires_grad=True), torch.tensor([random.random() for i in range(2*N)], requires_grad=True)))\n","#print(cpts)\n","#print(cpts[3])\n","print(type(cpts[3]))\n","#Stick together (concatenate: along the same dim)\n","inputs =torch.cat((inputinit, inputboundary))\n","outputs=torch.cat((outputinit, outputboundary))\n","\n","#print(inputs, outputs)\n"],"metadata":{"id":"0Dy6m3_N3NRO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719264442677,"user_tz":240,"elapsed":259,"user":{"displayName":"Youxuan Wei","userId":"06100885586754575702"}},"outputId":"80d74e6c-4f31-4dd8-c472-a2f5b920bc73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 2])\n","torch.Size([100])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["#Results\n","samples = torch.column_stack((torch.tensor([random.random() for i in range(10*N)]), torch.tensor([random.random() for i in range(10*N)])))\n","samplemodel=YWTry(2,1, epochs=30000, lr=5e-5).to(DEVICE)\n","samplemodel.Train(inputs, outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLVkORjo0oxK","executionInfo":{"status":"ok","timestamp":1719263922478,"user_tz":240,"elapsed":111320,"user":{"displayName":"Youxuan Wei","userId":"06100885586754575702"}},"outputId":"9f17048a-99cd-4120-ef1a-20474bf75479"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/30000, loss: 0.20\n","time elapsed: 0.009164810180664062\n","Epoch 3000/30000, loss: 0.11\n","time elapsed: 11.652799844741821\n","Epoch 6000/30000, loss: 0.11\n","time elapsed: 22.364651203155518\n","Epoch 9000/30000, loss: 0.11\n","time elapsed: 33.31175208091736\n","Epoch 12000/30000, loss: 0.11\n","time elapsed: 44.25128674507141\n","Epoch 15000/30000, loss: 0.11\n","time elapsed: 55.18576502799988\n","Epoch 18000/30000, loss: 0.11\n","time elapsed: 65.6930046081543\n","Epoch 21000/30000, loss: 0.11\n","time elapsed: 77.58977150917053\n","Epoch 24000/30000, loss: 0.11\n","time elapsed: 88.72513246536255\n","Epoch 27000/30000, loss: 0.11\n","time elapsed: 99.91305303573608\n"]},{"output_type":"execute_result","data":{"text/plain":["()"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["samplemodel.Model(torch.tensor([.5,.5]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSBH01MT03qx","executionInfo":{"status":"ok","timestamp":1718906842007,"user_tz":240,"elapsed":142,"user":{"displayName":"Youxuan Wei","userId":"06100885586754575702"}},"outputId":"13745a0b-81d6-4c76-f905-d88dd63db2d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.2272], grad_fn=<ViewBackward0>)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"kDGqzR7uNF2D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["///divider"],"metadata":{"id":"Vv9IXC4K0kLU"}},{"cell_type":"markdown","source":["try1:\n","epoch30000, lr1e-5,optimizer=adam,\n","Epoch 0/30000, loss: 0.39\n","Epoch 3000/30000, loss: 0.32\n","Epoch 6000/30000, loss: 0.27\n","Epoch 9000/30000, loss: 0.23\n","Epoch 12000/30000, loss: 0.19\n","Epoch 15000/30000, loss: 0.16\n","Epoch 18000/30000, loss: 0.14\n","Epoch 21000/30000, loss: 0.13\n","Epoch 24000/30000, loss: 0.13\n","Epoch 27000/30000, loss: 0.13\n","\n","\n","try2: epoch30000, lr1e-4,optimizer=adam,\n","Epoch 0/30000, loss: 0.20\n","Epoch 3000/30000, loss: 0.12\n","Epoch 6000/30000, loss: 0.12\n","Epoch 9000/30000, loss: 0.12\n","Epoch 12000/30000, loss: 0.12\n","Epoch 15000/30000, loss: 0.12\n","Epoch 18000/30000, loss: 0.12\n","Epoch 21000/30000, loss: 0.12\n","Epoch 24000/30000, loss: 0.12\n","Epoch 27000/30000, loss: 0.12\n","\n","\n","try3: same as above (but i added time stamps)\n","usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([300, 1])) that is different to the input size (torch.Size([300])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 0/30000, loss: 0.84\n","time elapsed: 0.008864164352416992\n","Epoch 3000/30000, loss: 0.14\n","time elapsed: 12.571324110031128\n","Epoch 6000/30000, loss: 0.13\n","time elapsed: 23.610451221466064\n","Epoch 9000/30000, loss: 0.13\n","time elapsed: 34.72315692901611\n","Epoch 12000/30000, loss: 0.13\n","time elapsed: 45.22088980674744\n","Epoch 15000/30000, loss: 0.13\n","time elapsed: 56.28272533416748\n","Epoch 18000/30000, loss: 0.13\n","time elapsed: 67.95624613761902\n","Epoch 21000/30000, loss: 0.13\n","time elapsed: 79.10966062545776\n","Epoch 24000/30000, loss: 0.13\n","time elapsed: 90.2882821559906\n","Epoch 27000/30000, loss: 0.13\n","time elapsed: 101.59162855148315\n","()\n","\n","\n","\n","try4: I added the loss_g b/c I was getting the user warning for the array sizes\n","\n","Also lr=5e-5\n","\n","Tweaked the physics loss to correctly compute Ut and Ux at any given input. For try 4 I tried to average over all the collocation pts, but WHY DOESN'T GRAD CALCULATE JACOBIAN AS A MULTIDIMERSIONAL TENSOR??. It only lets me compute the gradient at ONE COLOCATION POINT at one time. So then I had to sample it at random colocation points.\n","\n","Epoch 0/30000, loss: 0.20\n","time elapsed: 0.009164810180664062\n","Epoch 3000/30000, loss: 0.11\n","time elapsed: 11.652799844741821\n","Epoch 6000/30000, loss: 0.11\n","time elapsed: 22.364651203155518\n","Epoch 9000/30000, loss: 0.11\n","time elapsed: 33.31175208091736\n","Epoch 12000/30000, loss: 0.11\n","time elapsed: 44.25128674507141\n","Epoch 15000/30000, loss: 0.11\n","time elapsed: 55.18576502799988\n","Epoch 18000/30000, loss: 0.11\n","time elapsed: 65.6930046081543\n","Epoch 21000/30000, loss: 0.11\n","time elapsed: 77.58977150917053\n","Epoch 24000/30000, loss: 0.11\n","time elapsed: 88.72513246536255\n","Epoch 27000/30000, loss: 0.11\n","time elapsed: 99.91305303573608"],"metadata":{"id":"1NC3LL_WM4sr"}},{"cell_type":"code","source":["#visualazation\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(5, 5), dpi=300)\n","# input shape\n","n_temporal, n_spatial = 10, 2000\n","# combine (x, t) as a vector\n","v = np.zeros([n_spatial, 2]) # v[:, 0] = t, v[:, 1] = x\n","v[:, 1] = np.linspace(-1, +1, n_spatial)\n","# change t\n","for i in range(n_temporal):\n","    v[:, 0] = i/n_temporal\n","    plt.plot(v[:, 1], samplemodel.Model(torch.tensor(v)), label=f\"t = {i/N:.2f}\", lw=0.75)\n","\n","plt.legend(loc=\"upper right\", fontsize=5)\n","plt.xlim(-1, +1)\n","plt.ylim(-1, +1)\n","plt.ylabel(f\"u(t, x)\")\n","plt.xlabel(f\"x\")\n","plt.tight_layout()\n","plt.savefig(\"u-constant-time.png\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"18w6jvMdJ4sr","executionInfo":{"status":"error","timestamp":1719264780913,"user_tz":240,"elapsed":418,"user":{"displayName":"Youxuan Wei","userId":"06100885586754575702"}},"outputId":"d37cd196-1261-4964-f309-0a78a204a95b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 must have the same dtype, but got Double and Float","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-5a08b9009138>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_temporal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_temporal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplemodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"t = {i/N:.2f}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper right\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-72-a8e611e9a17c>\u001b[0m in \u001b[0;36mModel\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;31m#.detach().cpu().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-72-a8e611e9a17c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#it gives you the input as transformed by the hidden layers of the neural networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#prints out the final product. 'out' as tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1500 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["#define losses (not necessary?)\n","#MS loss on boundary conditions: from princeton tutorial\n","def loss_g(t_p, t_c):\n"," squared_diffs = (t_p - t_c)**2\n"," return squared_diffs.mean()\n","\n","#physics loss\n","def loss_f(inputs): #model is the neural network. I need to figure out the syntax\n","#should put cpts, the colocation pts, as the input\n","  nnpred=Model(inputs)\n","  Ut=grad(nnpred, inputs[:,1]) #grad against the time component, all rows, 2nd column\n","  Ux=grad(nnpred, inputs[:,1])\n","  eq = (Ut-nnpred*Ux)**2\n","  return eq.mean()\n","\n","#theowolf code\n","def physics_loss(model: torch.nn.Module):\n","    ts = torch.linspace(0, 1000, steps=1000,).view(-1,1).requires_grad_(True).to(DEVICE)\n","    temps = model(ts)\n","    dT = grad(temps, ts)[0]\n","    pde = R*(Tenv - temps) - dT\n","\n","    return torch.mean(pde**2)"],"metadata":{"id":"MMIaxf9UCzKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class YWModel(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(TinyModel, self).__init__()\n","\n","        self.linear1 = torch.nn.Linear(100, 200)\n","        self.activation = torch.nn.ReLU()\n","        self.linear2 = torch.nn.Linear(200, 10)\n","        self.softmax = torch.nn.Softmax()\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.activation(x)\n","        x = self.linear2(x)\n","        x = self.softmax(x)\n","        return x\n"],"metadata":{"id":"-bCSm_P2pf1b"},"execution_count":null,"outputs":[]}]}